<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Generative AI & LLM Engineering | Arash Nicoomanesh</title>

  <meta name="description" content="Custom LLM architecture, model optimization, and reliable engineering for high-stakes AI systems. Beyond simple API wrappers."/>
  <meta property="og:title" content="Generative AI & LLM Engineering"/>
  <meta property="og:description" content="Determinism, Neuro-Symbolic Logic, and High-Throughput Optimization."/>
  <meta property="og:type" content="website"/>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css"/>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet"/>
  
  <style>
    :root {
      --dark: #121212; --darker: #0a0a0a; --gray: #9ca3af;
      --accent: #ff6b00; --accent-hover: #e66000; --code-bg: #1e1e1e;
    }
    * { margin:0; padding:0; box-sizing:border-box; }
    html { scroll-behavior: smooth; }
    body { background: var(--darker); color: #eaf2fb; font-family: 'Inter', sans-serif; line-height: 1.6; -webkit-font-smoothing: antialiased; }
    img { max-width: 100%; display: block; }
    .container { max-width: 1100px; margin: 0 auto; padding: 0 20px; }
    
    /* ---------- header ---------- */
    header { position: sticky; top: 0; z-index: 100; background: rgba(0,0,0,0.8); backdrop-filter: blur(10px); border-bottom: 1px solid rgba(255,255,255,.05); }
    .header-inner { display: flex; align-items: center; justify-content: space-between; padding: 18px 0; }
    .logo { font-weight: 700; font-size: 1.3rem; display: flex; align-items: center; gap: 10px; color: #fff; text-decoration: none; }
    .logo i { color: var(--accent); }
    .back-btn { background: transparent; color: #cbd6df; border: 1px solid rgba(255,255,255,.1); padding: 8px 18px; border-radius: 50px; font-size: .9rem; text-decoration: none; display: inline-flex; align-items: center; gap: 8px; transition: .3s; }
    .back-btn:hover { border-color: var(--accent); color: var(--accent); }
    
    /* ---------- hero ---------- */
    .hero {
      padding: clamp(80px, 12vw, 120px) 0;
      text-align: center;
      background-image: 
        linear-gradient(rgba(0, 0, 0, 0.7), rgba(0, 0, 0, 0.9)),
        url('https://images.unsplash.com/photo-1620712943543-bcc4688e7485?q=80&w=2000&auto=format&fit=crop');
      background-size: cover;
      background-position: center;
      border-bottom: 1px solid rgba(255,255,255,.02);
    }
    .hero h1 { 
        font-size: clamp(2.5rem, 5vw, 4rem) !important; 
        font-weight: 800 !important; 
        line-height: 1.15 !important; 
        margin-bottom: 24px !important;
        color: #fff;
    }
    .hero p { 
        font-size: clamp(1.1rem, 2vw, 1.3rem) !important; 
        max-width: 900px !important; 
        margin: 0 auto 40px auto !important;
        color: #e2e8f0 !important; 
        font-weight: 400 !important; 
    }
    
    /* ---------- buttons ---------- */
    .btn-primary { background: var(--accent); color: #fff; padding: 14px 32px; border-radius: 6px; font-weight: 600; text-decoration: none; display: inline-flex; justify-content: center; align-items: center; gap: 10px; transition: .3s; border: none; cursor: pointer; font-size: 1rem; }
    .btn-primary:hover { background: var(--accent-hover); transform: translateY(-2px); box-shadow: 0 8px 25px rgba(255,107,0,.25); }
    .btn-submit { width: 100%; margin-top: 10px; }
    
    /* ---------- sections ---------- */
    section { padding: clamp(60px, 8vw, 90px) 0; }
    .grid-4 { display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; }
    @media(max-width: 950px){ .grid-4 { grid-template-columns: repeat(2, 1fr); gap: 24px; } }
    @media(max-width: 650px){ .grid-4 { grid-template-columns: 1fr; } }

    .card { background: rgba(30,30,30,0.6); border: 1px solid rgba(255,255,255,.05); border-radius: 12px; padding: 24px; transition: all 0.3s; }
    .card:hover { transform: translateY(-3px); border-color: rgba(255,107,0,0.3); box-shadow: 0 10px 30px rgba(0,0,0,0.4); }
    .card h3 { font-size: 1.2rem; margin-bottom: 14px; color: #fff; display: flex; align-items: center; gap: 10px; }
    .card h3 i { color: var(--accent); }
    .card p { color: #a8aeb3; font-size: 0.95rem; line-height: 1.6; }

    /* ---------- VERTICAL SHOWCASE STYLES ---------- */
    .vertical-showcase { display: grid; grid-template-columns: 1fr 1fr; gap: 40px; align-items: center; margin-bottom: 80px; }
    .vertical-showcase.reverse { direction: rtl; }
    .vertical-showcase.reverse > * { direction: ltr; }
    @media(max-width: 900px) { 
        .vertical-showcase { grid-template-columns: 1fr; margin-bottom: 60px; }
        .vertical-showcase.reverse { direction: ltr; }
    }
    
    .showcase-content h3 { font-size: 1.8rem; color: #fff; margin-bottom: 16px; display:flex; align-items:center; gap:12px; }
    .showcase-content h4 { color: var(--gray); font-size: 1.1rem; font-weight: 500; margin-bottom: 20px; }
    .showcase-content p { color: #cbd6df; margin-bottom: 16px; line-height: 1.7; }
    
    .tech-badge-container { display: flex; flex-wrap: wrap; gap: 8px; margin-top: 20px; }
    .tech-badge { background: rgba(255,107,0,0.1); color: var(--accent); border: 1px solid rgba(255,107,0,0.3); padding: 4px 10px; border-radius: 4px; font-size: 0.8rem; font-family: 'JetBrains Mono', monospace; font-weight: 600; }

    /* ---------- CODE WINDOWS ---------- */
    .mac-window { background: var(--code-bg); border-radius: 10px; border: 1px solid rgba(255,255,255,0.1); overflow: hidden; box-shadow: 0 20px 40px rgba(0,0,0,0.6); }
    .mac-header { background: #2d2d2d; padding: 12px 16px; display: flex; align-items: center; gap: 8px; border-bottom: 1px solid rgba(255,255,255,0.05); }
    .mac-dot { width: 12px; height: 12px; border-radius: 50%; }
    .mac-dot.red { background: #ff5f56; } .mac-dot.yellow { background: #ffbd2e; } .mac-dot.green { background: #27c93f; }
    .mac-title { margin-left: auto; color: #858585; font-size: 0.8rem; font-family: 'JetBrains Mono', monospace; }
    
    pre { padding: 20px; overflow-x: auto; font-family: 'JetBrains Mono', monospace; font-size: 0.85rem; line-height: 1.5; color: #d4d4d4; margin:0;}
    .keyword { color: #569cd6; } .string { color: #ce9178; } .comment { color: #6a9955; font-style: italic; } .func { color: #dcdcaa; } .class { color: #4ec9b0; }

    .live-terminal { background: #000; padding: 20px; border-radius: 10px; font-family: 'JetBrains Mono', monospace; font-size: 0.85rem; color: #00ff00; border: 1px solid rgba(0, 255, 0, 0.2); box-shadow: inset 0 0 15px rgba(0,255,0,0.05); line-height: 1.6; }
    
    @keyframes blinkCursor { 0%, 100% { opacity: 1; } 50% { opacity: 0; } }
    .blink-cursor { display: inline-block; width: 8px; height: 15px; background-color: #00ff00; vertical-align: middle; margin-left: 5px; animation: blinkCursor 1s step-end infinite; }

    /* ---------- cta band ---------- */
    .cta-band { background: #121212; text-align: center; padding: 70px 0; border-top: 2px solid var(--accent); }
    
    /* ---------- deliverables / form ---------- */
    .deliver-box { background: rgba(22,22,22,0.8); border: 1px solid rgba(255,255,255,.08); border-radius: 12px; padding: 40px; text-align: left; }
    .form-row { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 20px; }
    input, select, textarea { width: 100%; padding: 14px 16px; border-radius: 8px; background: rgba(0,0,0,0.5); border: 1px solid rgba(255,255,255,.1); color: #fff; font-family: inherit; font-size: 1rem; transition: all .3s; }
    input:focus, select:focus, textarea:focus { outline: none; border-color: var(--accent); box-shadow: 0 0 0 2px rgba(255,107,0,.15); }
    label { font-size: .9rem; color: #cbd6df; margin-bottom: 8px; display: block; font-weight: 500; }
    
    footer { text-align: center; padding: 30px 0; color: #6b7280; font-size: .9rem; border-top: 1px solid rgba(255,255,255,.05); }
    @media(max-width:700px){ .form-row { grid-template-columns: 1fr; } }
  </style>
</head>
<body>

<header>
  <div class="container">
    <div class="header-inner">
      <a href="../index.html" class="logo"><i class="fa-solid fa-microchip"></i>Arash Nicoomanesh</a>
      <a href="../index.html" class="back-btn"><i class="fa-solid fa-arrow-left-long"></i>Back to main</a>
    </div>
  </div>
</header>

<section class="hero">
  <div class="container">
    <h1>Generative AI & LLM Engineering</h1>
    <p>Determinism, Neuro-Symbolic Logic, and High-Throughput Optimization. Moving beyond API wrappers, we re-engineer model architectures for production scale. We optimize neural weights for latency, implement custom precision tuning, and design dedicated inference layers that drastically reduce compute costs without sacrificing reasoning quality.</p>
    <a href="#request" class="btn-primary">Optimize Your Inference <i class="fa-solid fa-arrow-right"></i></a>
  </div>
</section>

<section>
  <div class="container">
    <div class="vertical-showcase">
      <div class="showcase-content">
        <h3><i class="fa-solid fa-server"></i> High-Throughput Inference</h3>
        <h4>Escaping the HuggingFace Pipeline Bottleneck</h4>
        <p>Naive model deployment leads to GPU memory fragmentation and unacceptable Time-To-First-Token (TTFT). We implement advanced serving architectures using PagedAttention and continuous batching.</p>
        <p>By leveraging custom CUDA kernels and optimizing precision states (AWQ/GPTQ), we maximize hardware utilization, driving down the unit cost of every token generated in production.</p>
        <div class="tech-badge-container">
          <span class="tech-badge">vLLM</span>
          <span class="tech-badge">TensorRT</span>
          <span class="tech-badge">AWQ / GPTQ</span>
          <span class="tech-badge">Flash-Decoding</span>
          <span class="tech-badge">SGLang</span>
        </div>
              </div>
      
      <div class="live-terminal">
        > [INFO] Initializing vLLM Engine (GPU 0: NVIDIA H100)<br>
        > [INFO] Loading weights: meta-llama/Llama-3-70B-Instruct-AWQ<br>
        > [INFO] Quantization: AWQ (4-bit) | Precision: bfloat16<br>
        > [INFO] Allocating KV Cache (PagedAttention)...<br>
        > [INFO] Max sequence length: 8192 | Block size: 16<br>
        > [CUDA] Flash-Decoding activated for generation phase.<br>
        > [METRIC] TTFT: 142ms | TPOT: 18ms | Throughput: 4,200 tok/s<br>
        > [STATUS] Engine ready. Listening on port 8000...<span class="blink-cursor"></span>
      </div>
    </div>

    <div class="vertical-showcase reverse">
      <div class="showcase-content">
        <h3><i class="fa-solid fa-code"></i> Structured Generation</h3>
        <h4>Forcing LLMs to Obey Neuro-Symbolic Logic</h4>
        <p>LLMs are probabilistic text generators, which makes them inherently dangerous for enterprise automation. "Prompting" them to output JSON frequently fails in edge cases.</p>
        <p>We deploy frameworks that intervene directly at the logits level during the decoding process. By masking invalid tokens before they are sampled, we mathematically guarantee that the LLM output conforms perfectly to your required Pydantic schemas, RegEx, or SQL grammar.</p>
        <div class="tech-badge-container">
          <span class="tech-badge">Outlines</span>
          <span class="tech-badge">Guidance</span>
          <span class="tech-badge">DSPy</span>
          <span class="tech-badge">LMQL</span>
        </div>
      </div>
      
      <div class="mac-window">
        <div class="mac-header">
          <div class="mac-dot red"></div><div class="mac-dot yellow"></div><div class="mac-dot green"></div>
          <div class="mac-title">deterministic_routing.py</div>
        </div>
        <pre><code><span class="keyword">import</span> outlines
<span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field

<span class="comment"># Define the strict neuro-symbolic execution schema</span>
<span class="keyword">class</span> <span class="class">ExecutionPlan</span>(BaseModel):
    action: str = Field(pattern=<span class="string">"^(QUERY_DB|CALL_API|ESCALATE)$"</span>)
    confidence: float = Field(ge=<span class="number">0.0</span>, le=<span class="number">1.0</span>)
    parameters: dict

<span class="comment"># Bind model and constrain the logits sampling deterministically</span>
model = outlines.models.vllm(<span class="string">"mistralai/Mistral-7B-Instruct"</span>)
generator = outlines.generate.json(model, ExecutionPlan)

<span class="comment"># 100% Guaranteed to return a valid JSON matching the schema</span>
result = generator(<span class="string">"Evaluate user request: Calculate Q3 revenue."</span>)</code></pre>
      </div>
    </div>

    <div class="vertical-showcase">
      <div class="showcase-content">
        <h3><i class="fa-solid fa-layer-group"></i> Alignment & Fine-Tuning</h3>
        <h4>Domain Adaptation Without Catastrophic Forgetting</h4>
        <p>When off-the-shelf models fail at domain-specific reasoning (like clinical triage or financial ledger math), we align them to your proprietary data.</p>
        <p>Using Unsloth for ultra-fast gradient computation and techniques like DPO (Direct Preference Optimization), we teach models exactly *how* to reason within your domain, minimizing hallucination while drastically reducing cloud training costs.</p>
        <div class="tech-badge-container">
          <span class="tech-badge">Unsloth</span>
          <span class="tech-badge">LoRA / QLoRA</span>
          <span class="tech-badge">DPO / ORPO</span>
          <span class="tech-badge">CUDA Kernels</span>
        </div>
      </div>
      
      <div class="live-terminal">
        > [TRAIN] Initiating Unsloth QLoRA fine-tuning sequence...<br>
        > [MEMORY] Base Model: 7B | Loaded in 4-bit | VRAM footprint: 5.2GB<br>
        > [OPTIMIZE] Triton kernels enabled for RoPE and CrossEntropyLoss.<br>
        > [DATA] Loading Medical-Chain-Of-Thought Dataset (N=15,400)<br>
        > [EPOCH 1/3] Step 50/480 | Loss: 1.402 | LR: 2e-4<br>
        > [EPOCH 1/3] Step 100/480 | Loss: 0.984 | LR: 1.8e-4<br>
        > [ALIGN] Applying Direct Preference Optimization (DPO)...<br>
        > [EVAL] Reward margin increasing. Hallucination rate dropping.<br>
        > [SAVE] Exporting LoRA adapters to safetensors... DONE.<span class="blink-cursor"></span>
      </div>
    </div>
  </div>
</section>

<div class="cta-band">
  <div class="container">
    <h2 style="color:#fff;">Stop paying for bloated API wrappers.</h2>
    <p>Own your intelligence layer. Deploy optimized, deterministic models on your own infrastructure.</p>
    
    <div id="request" class="deliver-box" style="max-width: 700px; margin: 0 auto; margin-top:40px;">
      <h3>Request an Engineering Consultation</h3>
      <p style="color:#9ca3af;margin-bottom:24px;font-size:0.95rem;">Tell me about your current inference stack, latency bottlenecks, or fine-tuning requirements.</p>

      <form action="https://formspree.io/f/xwpnvzwl" method="POST">
        <div class="form-row">
          <div>
            <label>Your name *</label>
            <input name="name" type="text" required placeholder="Jane Doe">
          </div>
          <div>
            <label>Work email *</label>
            <input name="email" type="email" required placeholder="jane@company.com">
          </div>
        </div>

        <div style="margin-bottom:20px">
          <label>Company / organisation</label>
          <input name="organisation" placeholder="Acme Inc.">
        </div>

        <div style="margin-bottom:20px">
          <label>Primary Focus Area</label>
          <select name="capability">
            <option value="inference">Inference Optimization (vLLM, TensorRT)</option>
            <option value="structured">Structured Generation (Outlines, DSPy)</option>
            <option value="finetuning">Custom Fine-Tuning (Unsloth, DPO, LoRA)</option>
            <option value="architecture">Full LLM Pipeline Architecture</option>
          </select>
        </div>

        <div style="margin-bottom:24px">
          <label>Describe your engineering bottleneck *</label>
          <textarea name="message" required placeholder="e.g. We are experiencing high latency and cost with GPT-4, and need to deploy a fast, deterministic open-weight model..." style="min-height:120px"></textarea>
        </div>

        <input type="hidden" name="service" value="LLM Engineering">
        <input type="hidden" name="_subject" value="Website lead: LLM Engineering">
        <input type="hidden" name="_next" value="https://aragit.github.io/thanks.html">
        <input type="text" name="hp_field" style="display:none" tabindex="-1" autocomplete="off">

        <button type="submit" class="btn-primary btn-submit"><i class="fa-solid fa-server"></i> Submit Requirements</button>
      </form>
    </div>
  </div>
</div>

<footer>
  <div class="container">
    © <span id="yr"></span> Arash Nicoomanesh · Agentic AI Architecture
  </div>
</footer>

<script>
  document.getElementById('yr').textContent = new Date().getFullYear();
  const u = new URLSearchParams(location.search);
  ['utm_source','utm_medium','utm_campaign'].forEach(p=>{
    const v=u.get(p),el=document.createElement('input'); 
    if(v){el.type='hidden';el.name=p;el.value=v;document.querySelector('form').appendChild(el);}
  });
</script>
</body>
</html>
